# What is the **k-nearest neighbors** algorithm for _classification_?

The **K-nearest neighbors** algorithm used for classification, functions when an unclassified item enters the data set, so it uses its nearest neighbors to approximate its classification. In the real world, the **KNN** algorithm helps services such as Netflix make recommendations to users. By using ratings and then calculating the distance between users' ratings using the Pythagorean formula, it can then make recommendations to different users. Moreover, **KNN** is useful in predicting a response using regression. By averaging a users' neighbors' ratings, it could predict the user's rating. Instead of calculating the distance, a **KNN** can calculate a _cosine similarity_, which measures the angle instead of the distance between two vectors.

## What is **machine learning**?

**KNN** features prominently in **machine learning**, in other words making a computer smarter. An example would be a recommendation engine. Feature extraction depends on what the machine is learning, for example in the recommendation engine's case, a feature would be the movies ratings. Whereas, for **OCR** it would be lines, curves for characters.

### What is **OCR**?

**Optical character recognition** or **OCR** is when a computer recognizes a character from a picture. It also uses a **KNN** algorithm looking at pictures and interprets the original picture accordingly. The same principle of feature extraction applies with **KNN** for speech and face recognition, etc...albeit in a much more complicated way. When a machine is learning, it needs to go through a _training_ phase, which it accumulates features and data to be able make recommendations.
