# What is **Unicode**, **UTF-8**, **ASCII** and how do emojis work?

Initially, the first notable character set was **ASCII**. It represented unaccented English characters using a number from 32 to 127 using a mere 7 bits out of an 8-bit byte, which was what computers used at the time. Next, with the advent of the internet came the invention of **Unicode**. It attempted to include all character sets as **code points** written as U+0639 with the U+ referring to **Unicode** and the numbers being **hexadecimal** values. Then, another method of storing **Unicode code points** or (**encoding Unicode**) came along in the form of **UTF-8** using 8-bit bytes and representing **code points** from 0-127 in a single byte, with **code points** over 128 stored in 2, 3 and up to 6 bytes a character. In **UTF-8**, English text looks like it did in **ASCII** thus helping in the way of continuity. Other systems for **encoding Unicode** include **UTF-16** using 16-bit bytes, **UCS-2** using two byte characters, and even **UTF-7** among others. Emojis are a part of **Unicode** nowadays with them becoming more ubiquitous, they're represented using similar methods of encoding to letters like **UTF-8**.
